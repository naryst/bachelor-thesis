@ARTICLE{A,
  author = {A. A. Aardvark},
  title = {Article title},
  journal = {Journal Title},
  year = {1900},
  volume = {1},
  pages = {1--8},
  number = {1}
}

@incollection{B,
  pages = {627-637},
  title = {Title of chapter in the book,},
  author = {Sweetser, Penny},
  crossref = {crref}
}
@book{crref,
  title = {Title of Published Book},
  booktitle = {Title of Published Book},
  publisher = {Charles River Media},
  year = {2004},
  address = {Hingham, Massachusetts, USA},
  edition = {1}
}

@ARTICLE{C,
  author = {A. A. Abramson and B. B. Barbie and C. C. Rider},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  volume = {1},
  pages = {192--244},
  number = {1}
}

@ARTICLE{D,
  author = {J.K.Author},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  month = {6},
  volume = {1},
  pages = {192--244},
  number = {1},
  note="Accessed: June 19, 2005. doi: 10.1109/TTHZ.2016.2544142. [Online]. Available: \url{https://ieeexplore.ieee.org/document/7463081}"
}

@CONFERENCE{F,
  author       = "J\dot K\dot Author",
  title        = "Title of paper",
  booktitle    = "Abbreviated Name of Conf.",
  note         = "1900, pp. 16--19. Accessed: June 19, 2005. [Online]. Available: \url{http://www.computer.org/csdl/proceedings/dac/2003/2394/00/2394001-abs.html}",
}


@article{devlin2018bert,
  title   = {Bert: Pre-training of deep bidirectional transformers for language understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal = {arXiv preprint arXiv:1810.04805},
  year    = {2018}
}

@inproceedings{dong2022fira,
  title     = {FIRA: fine-grained graph-based code change representation for automated commit message generation},
  author    = {Dong, Jinhao and Lou, Yiling and Zhu, Qihao and Sun, Zeyu and Li, Zhilin and Zhang, Wenjie and Hao, Dan},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering},
  pages     = {970--981},
  year      = {2022}
}

Improving language understand-
ing by generative pre-training
@article{eliseeva2023commit,
  title   = {From Commit Message Generation to History-Aware Commit Message Completion},
  author  = {Eliseeva, Aleksandra and Sokolov, Yaroslav and Bogomolov, Egor and Golubev, Yaroslav and Dig, Danny and Bryksin, Timofey},
  journal = {arXiv preprint arXiv:2308.07655},
  year    = {2023}
}

@article{jung2021commitbert,
  title   = {Commitbert: Commit message generation using pre-trained programming language model},
  author  = {Jung, Tae-Hwan},
  journal = {arXiv preprint arXiv:2105.14242},
  year    = {2021}
}

@article{liu2020atom,
  title     = {ATOM: Commit message generation based on abstract syntax tree and hybrid ranking},
  author    = {Liu, Shangqing and Gao, Cuiyun and Chen, Sen and Nie, Lun Yiu and Liu, Yang},
  journal   = {IEEE Transactions on Software Engineering},
  volume    = {48},
  number    = {5},
  pages     = {1800--1817},
  year      = {2020},
  publisher = {IEEE}
}

@article{liu2022commitbart,
  title   = {Commitbart: A large pre-trained model for github commits},
  author  = {Liu, Shangqing and Li, Yanzhou and Xie, Xiaofei and Liu, Yang},
  journal = {arXiv preprint arXiv:2208.08100},
  year    = {2022}
}

@inproceedings{papineni2002bleu,
  title     = {Bleu: a method for automatic evaluation of machine translation},
  author    = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle = {Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages     = {311--318},
  year      = {2002}
}

@article{radford2018improving,
  title     = {Improving language understanding by generative pre-training},
  author    = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year      = {2018},
  publisher = {OpenAI}
}

@article{roziere2023code,
  title   = {Code llama: Open foundation models for code},
  author  = {Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal = {arXiv preprint arXiv:2308.12950},
  year    = {2023}
}

@article{shi2022race,
  title   = {RACE: Retrieval-Augmented Commit Message Generation},
  author  = {Shi, Ensheng and Wang, Yanlin and Tao, Wei and Du, Lun and Zhang, Hongyu and Han, Shi and Zhang, Dongmei and Sun, Hongbin},
  journal = {arXiv preprint arXiv:2203.02700},
  year    = {2022}
}

@inproceedings{tao2021evaluation,
  title        = {On the evaluation of commit message generation models: An experimental study},
  author       = {Tao, Wei and Wang, Yanlin and Shi, Ensheng and Du, Lun and Han, Shi and Zhang, Hongyu and Zhang, Dongmei and Zhang, Wenqiang},
  booktitle    = {2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  pages        = {126--136},
  year         = {2021},
  organization = {IEEE}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@article{zhang2019bertscore,
  title   = {Bertscore: Evaluating text generation with bert},
  author  = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal = {arXiv preprint arXiv:1904.09675},
  year    = {2019}
}

@inproceedings{keles2023computational,
  title={On the computational complexity of self-attention},
  author={Keles, Feyza Duman and Wijewardena, Pruthuvi Mahesakya and Hegde, Chinmay},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={597--619},
  year={2023},
  organization={PMLR}
}

@inproceedings{liu2018neural,
  title={Neural-machine-translation-based commit message generation: how far are we?},
  author={Liu, Zhongxin and Xia, Xin and Hassan, Ahmed E and Lo, David and Xing, Zhenchang and Wang, Xinyu},
  booktitle={Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages={373--384},
  year={2018}
}

@article{wang2021codet5,
  title={Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2109.00859},
  year={2021}
}

@article{wang2023codet5+,
  title={Codet5+: Open code large language models for code understanding and generation},
  author={Wang, Yue and Le, Hung and Gotmare, Akhilesh Deepak and Bui, Nghi DQ and Li, Junnan and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2305.07922},
  year={2023}
}

@article{post2018call,
  title={A call for clarity in reporting BLEU scores},
  author={Post, Matt},
  journal={arXiv preprint arXiv:1804.08771},
  year={2018}
}

@inproceedings{
he2021deberta,
title={DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION},
author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=XPZIaotutsD}
}

@article{wang2021context,
  title={Context-aware retrieval-based deep commit message generation},
  author={Wang, Haoye and Xia, Xin and Lo, David and He, Qiang and Wang, Xinyu and Grundy, John},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={30},
  number={4},
  pages={1--30},
  year={2021},
  publisher={ACM New York, NY, USA}
}
